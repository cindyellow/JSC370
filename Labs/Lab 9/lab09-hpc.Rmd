---
title: "Lab 9 - HPC"
output: html_document
link-citations: yes
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(eval = F)
```

```{r, include=T}
library(parallel)
library(foreach)
library(doParallel)
```

# Learning goals

In this lab, you are expected to learn/put in practice the following skills:

- Evaluate whether a problem can be parallelized or not.
- Practice with the parallel package.
- Use Rscript to submit jobs
- Practice your skills with Git.

## Firstly: check out your hardware

Open up task manager and look at your CPU, GPU

Try these commands out (you may need to install them on your machine first)
* `top` or `htop` (human-readable top)
* `lshw -C display`
* `nvidia-smi` (only applies to nvidia products)

Or, in R: `doParallel::detectCores()`

## Problem 1: Think

Give yourself a few minutes to think about what you learned about parallelization. List three
examples of problems that you believe may be solved using parallel computing,
and check for packages on the HPC CRAN task view that may be related to it.

Parallelization can be used to speed up processes in our code. Some of the issues it can address include:
* Cross Validation (`carat`, `mlr`)
* XGBoost (`xgboost`): performing more efficient gradient boosting
* `foreach`: speeds up for loop execution

## Problem 2: Pre-parallelization

The following functions can be written to be more efficient without using
parallel:

1. This function generates a `n x k` dataset with all its entries having a Poisson distribution with mean `lambda`.



```{r p2-fun1}
fun1 <- function(n = 100, k = 4, lambda = 4) {
  x <- NULL
  
  for (i in 1:n)
    # Gives integers generated from Poisson distribution
    x <- rbind(x, rpois(k, lambda))
  
  return(x)
}

fun1alt <- function(n = 100, k = 4, lambda = 4) {
  # Make a matrix of n*k draws
  matrix(rpois(n*k,lambda), ncol=k)
}

# Benchmarking
microbenchmark::microbenchmark(
  fun1(),
  fun1alt()
)
```

How much faster?

* It is faster by a lot, on average around 465 microseconds.

2.  Find the column max (hint: Checkout the function `max.col()`).

```{r p2-fun2}
# Data Generating Process (10 x 10,000 matrix)
set.seed(1234)
x <- matrix(rnorm(1e4), nrow=10)

# Find each column's max value
fun2 <- function(x) {
  apply(x, 2, max)
}

fun2alt <- function(x) {
  # column binding
  x[cbind(max.col(t(x)), 1:ncol(x))]
}

# Benchmarking
ans <- microbenchmark::microbenchmark(
  fun2(x),
  fun2alt(x)
  )

plot(ans)
```

## Problem 3: Parallelize everyhing

We will now turn our attention to non-parametric 
[bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)).
Among its many uses, non-parametric bootstrapping allow us to obtain confidence
intervals for parameter estimates without relying on parametric assumptions.

The main assumption is that we can approximate many experiments by resampling
observations from our original dataset, which reflects the population. 

This function implements the non-parametric bootstrap:

```{r p3-boot-fun}
my_boot <- function(dat, stat, R, ncpus = 1L) {
  
  # Getting the random indices
  n <- nrow(dat)
  idx <- matrix(sample.int(n, n*R, TRUE), nrow=n, ncol=R)
 
  # STEP 1: Making the cluster using `ncpus`; distribute tasks across course
  cl <- makePSOCKcluster(ncpus)
  
  # STEP 2: Export the cluster
  clusterExport(cl, varlist = c("idx", "dat", "stat"), envir = environment())
  
  # Ensures each bootstrap starts with a separate seed
  # clusterSetRNGStream(cl, 370)


  # STEP 3: Evaluate
  ans <- parLapply(cl, seq_len(R), function(i) {
    stat(dat[idx[,i], , drop=FALSE])
  })
  
  # Coercing the list into a matrix
  ans <- do.call(rbind, ans)
  
  # STEP 4: Close the cluster
  #Stops collisions from happening
  stopCluster(cl)
  
  ans
  
}
```

1. Use the previous pseudocode, and make it work with parallel. Here is just an example
for you to try:

```{r p3-test-boot}
# Bootstrap of a linear regression model
my_stat <- function(d){
  return(coef(lm(y~x, data=d)))
}

# DATA SIM
set.seed(1)
# Size of data
n <- 500 
# Number of bootstraps
R <- 1e4
x <- cbind(rnorm(n)) 
y <- x*5 + rnorm(n)

# Check if we get something similar as lm
# R's way
ans0 <- confint(lm(y~x))

# Our method implemented from scratch
ans1 <- my_boot(dat = data.frame(x=x,y=y), stat=my_stat, R=R, ncpus=2)

ans0
ans1
```

2. Check whether your version actually goes faster than the non-parallel version:


```{r benchmark-problem3}

```

## Problem 4: Compile this markdown document using Rscript

Once you have saved this Rmd file, try running the following command
in your terminal:

```bash
Rscript --vanilla -e 'rmarkdown::render("[full-path-to-your-Rmd-file.Rmd]")' &
```

Where `[full-path-to-your-Rmd-file.Rmd]` should be replace with the full path to
your Rmd file... :).


